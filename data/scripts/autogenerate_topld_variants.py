# Autogenerate variants from TopLD that are not in FAVOR

# Instructions:
# 1. Install AWS CLI and configure it with appropriate credentials
# 2. Run: pypy3 autogenerate_topld_variants.py
# 3. The script will create one JSONL file for each chromosome with the missing variants
# 4. Combine all files into a single file: cat chr*.jsonl > autogenerated_topld_variants.jsonl
# 5. Remove duplicated lines: awk '!seen[$0]++' autogenerated_topld_variants.jsonl > autogenerated_topld_variants_uniq.jsonl
# 6. Add keys and spdi + hgvs by using the `add_key_spdi_hgvs` function. It's a lot faster to generate the file above and then create the keys later.

import os
import pickle
import json

S3 = 's3://igvf-catalog-parsed-collections/variants/'
FAVOR = 'favor_chrC_spdi_key_format.jsonl'
TOPLDs = ['topld_eur_chrC_key.jsonl', 'topld_eas_chrC_key.jsonl',
          'topld_afr_chrC_key.jsonl', 'topld_sas_chrC_key.jsonl']


def add_key_spdi_hgvs(input_file, output_file):
    from ga4gh.vrs.extras.translator import AlleleTranslator
    from ga4gh.vrs.dataproxy import create_dataproxy
    from biocommons.seqrepo import SeqRepo
    import sys
    sys.path.append(os.path.abspath(
        os.path.join(os.path.dirname(__file__), '..')))
    from adapters.helpers import build_spdi, build_hgvs_from_spdi

    dp = create_dataproxy(
        'seqrepo+file:///usr/local/share/seqrepo/2024-12-20')
    seq_repo = SeqRepo('/usr/local/share/seqrepo/2024-12-20')
    translator = AlleleTranslator(data_proxy=dp)

    output = open(output_file, 'w+')

    for line in open(input_file, 'r'):
        data = json.loads(line)

        chrm = data['chr']
        pos = data['pos']
        ref = data['ref']
        alt = data['alt']

        variation_type = 'SNP'
        if len(ref) < len(alt):
            variation_type = 'insertion'
        elif len(ref) > len(alt):
            variation_type = 'deletion'

        spdi = build_spdi(
            chrm,
            pos,
            ref,
            alt,
            translator,
            seq_repo
        )

        hgvs = build_hgvs_from_spdi(spdi)
        allele = translator.translate_from(spdi, 'spdi')
        allele_vrs_digest = allele.digest

        data['variantion_type'] = variation_type
        data['spdi'] = spdi
        data['hgvs'] = hgvs
        data['_key'] = spdi if len(spdi) < 254 else allele_vrs_digest

        output.write(json.dumps(data) + '\n')

    output.close()


def load_favor(chr):
    favor = FAVOR.replace('C', str(chr))
    pickle_path = 'favor_chr' + str(chr) + '_keys.pickle'

    if os.path.exists(pickle_path):
        with open(pickle_path, 'rb') as inputt:
            return set(pickle.load(inputt))

    if not os.path.exists(favor):
        os.system('aws s3 cp ' + S3 + favor + ' .')

    ids = []
    for line in open(favor, 'r'):
        data = json.loads(line)
        ids.append(data['_key'])

    with open(pickle_path, 'wb') as output:
        pickle.dump(ids, output)

    os.remove(favor)

    return set(ids)


def create_variant(data):
    variant_data = data.split(':')
    return {
        'chr': variant_data[0],
        'pos': int(variant_data[1]),
        'ref': variant_data[2],
        'alt': variant_data[3],
        'source': 'Autogenerated from TopLD',
        'source_url': 'http://topld.genetics.unc.edu/'
    }


def process_chr(chr):
    favor_keys = load_favor(chr)

    output = open('chrC.jsonl'.replace('C', chr), 'w+')

    for topld in TOPLDs:
        topld_path = topld.replace('C', str(chr))

        if not os.path.exists(topld_path):
            os.system('aws s3 cp ' + S3.replace('variants/',
                      'variants_variants/') + topld_path + ' .')

        for line in open(topld_path, 'r'):
            data = json.loads(line)

            if data['_from'].split('variants/')[1] not in favor_keys:
                if data['variant_1_rsid'].startswith('chr'):
                    variant = create_variant(data['variant_1_rsid'])
                    output.write(json.dumps(variant) + '\n')

            if data['_to'].split('variants/')[1] not in favor_keys:
                if data['variant_2_rsid'].startswith('chr'):
                    variant = data['variant_2_rsid'].split(':')
                    output.write(json.dumps(variant) + '\n')

        os.remove(topld_path)

    output.close()


[process_chr(c) for c in range(1, 23) + ['X']]

# posterior processing:
# add_key_spdi_hgvs('autogenerated_topld_variants_uniq.jsonl', 'autogenerated_topld_variants_with_keys.jsonl')
